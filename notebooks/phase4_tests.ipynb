{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTAP_ML Phase 4 Experiment Template\n",
    "This template allows the BTAP_ML system to be tested in a notebook setting. The first portion can preprocess data to then be reused for any future tests.   \n",
    "Currently the notebook requires changes to be made to the actual BTAP_ML files before the experiments are run, but these changes should never be committed, only\n",
    "done for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# If being run from the notebooks directory, access the src directory\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import preprocessing as pre\n",
    "import models.training_model as tr_model\n",
    "import feature_selection as fs\n",
    "import predict as pred\n",
    "import config as config\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re \n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-time preprocessing per test scenario\n",
    "Run the following blocks of code to preprocess the data and extract the output files. Note that some manual changes may be needed and are commented accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can just use the absolute path here for the input_config.yml file\n",
    "#config_file = 'H:\\\\btap_ml\\\\src\\\\input_config.yml'\n",
    "config_file = 'C:\\\\Users\\\\duttsap\\\\Documents\\\\btap_ml_costing\\\\src\\\\input_config.yml'\n",
    "\n",
    "# Must point to where the files are held\n",
    "DOCKER_INPUT_PATH = config.Settings().APP_CONFIG.DOCKER_INPUT_PATH\n",
    "INPUT_CONFIG_FILENAME = \"input_config.yml\"\n",
    "random_seed = 1\n",
    "# Load the settings\n",
    "settings = config.Settings()\n",
    "# Set the perform_param_search parameter to 'no', this is hard-coded since we\n",
    "# want to leave the infrastructure for it in, but remove the ability to use it for now\n",
    "perform_param_search = 'no'\n",
    "# Begin by loading the config file\n",
    "cfg = config.get_config(config_file)\n",
    "random_seed = cfg.get(config.Settings().APP_CONFIG.RANDOM_SEED)\n",
    "# If the energy or building electricity files are not provided, load the files\n",
    "\n",
    "hourly_energy_electric_file = cfg.get(config.Settings().APP_CONFIG.ENERGY_PARAM_FILES)[0]\n",
    "building_params_electric_file = cfg.get(config.Settings().APP_CONFIG.BUILDING_PARAM_FILES)[0]\n",
    "hourly_energy_gas_file = cfg.get(config.Settings().APP_CONFIG.ENERGY_PARAM_FILES)[1]\n",
    "building_params_gas_file = cfg.get(config.Settings().APP_CONFIG.BUILDING_PARAM_FILES)[1]\n",
    "val_hourly_energy_file = cfg.get(config.Settings().APP_CONFIG.VAL_ENERGY_PARAM_FILE)\n",
    "val_building_params_file = cfg.get(config.Settings().APP_CONFIG.VAL_BUILDING_PARAM_FILE)\n",
    "estimator_type = cfg.get(config.Settings().APP_CONFIG.ESTIMATOR_TYPE)\n",
    "perform_param_search = cfg.get(config.Settings().APP_CONFIG.PARAM_SEARCH)\n",
    "selected_model_type = cfg.get(config.Settings().APP_CONFIG.SELECTED_MODEL_TYPE)\n",
    "\n",
    "# Identify the training processes to be taken and whether the updated model should\n",
    "# be used for the specified training (energy and/or costing)\n",
    "TRAINING_PROCESSES = [[config.Settings().APP_CONFIG.ENERGY, True],\n",
    "                        [config.Settings().APP_CONFIG.COSTING, True]]\n",
    "\n",
    "# Create directory to hold all data for the run (datetime/...)\n",
    "# If used, copy the config file within the directory to log the input values\n",
    "output_path_root = config.Settings().APP_CONFIG.DOCKER_OUTPUT_PATH\n",
    "# With Windows, the colon may cause issues depending on how the\n",
    "# dependencies work with them, thus they are removed\n",
    "output_path_root = Path(output_path_root).joinpath(settings.APP_CONFIG.TRAIN_BUCKET_NAME + str(datetime.now()).replace(\":\", \"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all the data in the verification data structure\n",
    "input_model = tr_model.TrainingModel(input_prefix=DOCKER_INPUT_PATH,\n",
    "                                     #config_file = 'C:\\\\Users\\\\duttsap\\\\Documents\\\\btap_ml\\\\input\\\\input_config.yml',\n",
    "                                    config_file='input_config.yml',\n",
    "                                    random_seed=random_seed,\n",
    "                                    building_param_files=[building_params_electric_file,\n",
    "                                                          building_params_gas_file],\n",
    "                                    energy_param_files=[hourly_energy_electric_file,\n",
    "                                                        hourly_energy_gas_file],\n",
    "                                    val_hourly_energy_file=val_hourly_energy_file,\n",
    "                                    val_building_params_file=val_building_params_file,\n",
    "                                    skip_file_preprocessing=False,\n",
    "                                    preprocessed_data_file='',\n",
    "                                    estimator_type=estimator_type,\n",
    "                                    skip_feature_selection=False,\n",
    "                                    selected_features_file='',\n",
    "                                    perform_param_search='no',\n",
    "                                    skip_model_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_file_preprocessing = True\n",
    "# Will need to change one config.py value (i.e. remove one of the two keys and call the below cell twice)\n",
    "training_processes = ['costing'] # ['costing']\n",
    "output_path_root = 'preprocessed_outputs/'#'preprocessed_outputs_gas/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For costing, change DOCKER_SRC_PATH: str = 'src/' in src/config.py to DOCKER_SRC_PATH: str = #'../src/' \n",
    "for training_process in training_processes:\n",
    "    # Change the output path to be an existing folder (i.e. preprocessed_outputs/)\n",
    "    output_path = output_path_root + training_process\n",
    "\n",
    "    config.create_directory(str(output_path))\n",
    "\n",
    "    preprocessed_data_file = pre.main(config_file=input_model.config_file,\n",
    "                            process_type=training_process,\n",
    "                            hourly_energy_electric_file=input_model.energy_param_files[0],\n",
    "                            building_params_electric_file=input_model.building_param_files[0],\n",
    "                            val_hourly_energy_file=input_model.val_hourly_energy_file,\n",
    "                            val_building_params_file=input_model.val_building_params_file,\n",
    "                            hourly_energy_gas_file=input_model.energy_param_files[1],\n",
    "                            building_params_gas_file=input_model.building_param_files[1],\n",
    "                            output_path='preprocessed_outputs_gas/' + training_process,\n",
    "                            preprocess_only_for_predictions=False,\n",
    "                            random_seed=input_model.random_seed,\n",
    "                            building_params_folder='',\n",
    "                            start_date='',\n",
    "                            end_date='',\n",
    "                            ohe_file='',\n",
    "                            cleaned_columns_file='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing file relative path \n",
    "input_model.preprocessed_data_file = 'preprocessed_outputs\\\\costing\\\\preprocessing\\\\preprocessing.json'# 'preprocessed_outputs_gas\\\\energy\\\\preprocessing\\\\preprocessing.json'\n",
    "# Can change whether energy or costing is being tested \n",
    "training_process = 'costing' # energy or costing\n",
    "output_path = '..\\\\'+'output'+'\\\\'+str(Path(output_path_root)) + '\\\\' +training_process + '\\\\' + selected_model_type\n",
    "config.create_directory(str(output_path))\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "input_model.selected_features_file = fs.main(input_model.config_file,\n",
    "                                            input_model.preprocessed_data_file,\n",
    "                                            input_model.estimator_type,\n",
    "                                            output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model.selected_features_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "model_path, train_results = pred.main(input_model.config_file,\n",
    "                                        training_process,\n",
    "                                        input_model.preprocessed_data_file,\n",
    "                                        input_model.selected_features_file,\n",
    "                                        selected_model_type,\n",
    "                                        input_model.perform_param_search,\n",
    "                                        output_path,\n",
    "                                        input_model.random_seed,\n",
    "                                        input_model.building_param_files[0],\n",
    "                                        input_model.building_param_files[1],\n",
    "                                        input_model.val_building_params_file,\n",
    "                                        True,\n",
    "                                        True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = r'..\\output\\preprocessed_outputs\\costing\\rf\\model_training\\training_results.json' # r'..\\output\\preprocessed_outputs_gas\\energy\\model_training\\training_results.json'\n",
    "with open(json_file_path, 'r') as j:\n",
    "     contents = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annual_metrics(annual_keys):\n",
    "    contents_first_set = contents.copy()\n",
    "    for keys in contents.keys():\n",
    "        if keys not in annual_keys:\n",
    "            del contents_first_set[keys]\n",
    "               \n",
    "    annual_results_df = pd.DataFrame(contents_first_set).transpose()\n",
    "    annual_results_df.index.names = ['Metric type']\n",
    "    return annual_results_df\n",
    "\n",
    "def create_building_metrics(building_keys):\n",
    "    contents_building_set = contents.copy()\n",
    "    for keys in contents.keys():\n",
    "        if keys not in building_keys:\n",
    "            del contents_building_set[keys]\n",
    "           \n",
    "    building_results_df = pd.DataFrame(contents_building_set).transpose()\n",
    "    building_results_df[['Building Type', 'Mean actual costing', 'Mean predicted costing', 'MAE', 'MSE']] = pd.DataFrame(building_results_df[0].tolist(), index= building_results_df.index)\n",
    "    building_results_df = building_results_df.drop([0], axis=1)\n",
    "    building_results_df.index.names = ['Metric type']\n",
    "    return building_results_df\n",
    "\n",
    "def create_climate_metrics(climate_keys):\n",
    "    contents_climate_set = contents.copy()\n",
    "    for keys in contents.keys():\n",
    "        if keys not in climate_keys:\n",
    "            del contents_climate_set[keys]\n",
    "    \n",
    "    climate_results_df = pd.DataFrame(contents_climate_set).transpose()\n",
    "    climate_results_df_0, climate_results_df_1 = climate_results_df[0].reset_index(), climate_results_df[1].reset_index()\n",
    "    climate_results_df_0[['Climate File', 'Mean actual costing', 'Mean predicted costing', 'MAE', 'MSE']] = pd.DataFrame(climate_results_df_0[0].tolist(), index= climate_results_df_0.index)\n",
    "    climate_results_df_1[['Climate File', 'Mean actual costing', 'Mean predicted costing', 'MAE', 'MSE']] = pd.DataFrame(climate_results_df_1[1].tolist(), index= climate_results_df_1.index)\n",
    "    climate_results_df_0 = climate_results_df_0.drop([0], axis=1)\n",
    "    climate_results_df_1 = climate_results_df_1.drop([1], axis=1)\n",
    "    climate_results_df = pd.concat([climate_results_df_0, climate_results_df_1])\n",
    "    climate_results_df.index = climate_results_df[\"index\"]\n",
    "    climate_results_df.index.names = ['Metric type']\n",
    "    climate_results_df = climate_results_df.drop(['index'], axis=1)\n",
    "    return climate_results_df\n",
    "\n",
    "def parse_metrics(file_name):\n",
    "    annual_regex = re.compile(\".*annual.*\")\n",
    "    building_regex = re.compile(\".*building.*\")\n",
    "    climate_regex = re.compile(\".*climate.*\")\n",
    "    annual_keys = list(filter(annual_regex.match, contents.keys()))\n",
    "    building_keys = list(filter(building_regex.match, contents.keys()))\n",
    "    climate_keys = list(filter(climate_regex.match, contents.keys()))\n",
    "\n",
    "    annual_metrics = create_annual_metrics(annual_keys)\n",
    "    building_metrics = create_building_metrics(building_keys)\n",
    "    climate_metrics = create_climate_metrics(climate_keys)\n",
    "\n",
    "    file_name = file_name\n",
    "\n",
    "    annual_metrics.to_csv(file_name)\n",
    "    empty_df_1 = pd.DataFrame(columns=annual_metrics.columns)\n",
    "    empty_df_1.to_csv(file_name, mode='a', header = False)\n",
    "    building_metrics.to_csv(file_name, mode='a')\n",
    "    empty_df_2 = pd.DataFrame(columns=building_metrics.columns)\n",
    "    empty_df_2.to_csv(file_name, mode='a', header = False)\n",
    "    climate_metrics.to_csv(file_name, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"costing_rf.csv\"\n",
    "parse_metrics(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btap-env",
   "language": "python",
   "name": "btap-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
